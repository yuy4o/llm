{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4bf7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"empty\"\n",
    "os.environ[\"OPENAI_CHAT_MODEL_ID\"] = \"Qwen3-14B\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"http://172.27.221.3:12000/v1\"\n",
    "os.environ[\"OPENAI_RESPONSES_MODEL_ID\"] = \"Qwen3-14B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e0a636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked for a TLDR of the Three Laws of Robotics in exactly 5 words. Let me recall the original Three Laws from Asimov. The first law is about not injuring humans, the second is obeying human orders, and the third is self-preservation. \n",
      "\n",
      "The challenge is to condense these into five words. Let me think. Maybe start with \"Protect humans, obey orders, self-preserve.\" Wait, that's 5 words? Let's count: Protect (1), humans (2), obey (3), orders (4), self-preserve (5). Yes. That covers all three laws. But is \"self-preserve\" the best way to phrase the third law? The original says \"protect its own existence,\" so \"self-preserve\" is accurate. \n",
      "\n",
      "Alternatively, could it be \"Human safety, obedience, self-preservation\"? That's also five words. But maybe the user wants the key verbs. The original answer given by the assistant was \"Protect humans, obey orders, self-preserve.\" That seems concise and captures each law. Let me check if there's a more concise way. Maybe \"Human first, obey, survive.\" But that's a bit vague. The original answer is better. I think that's the best fit.\n",
      "</think>\n",
      "\n",
      "Protect humans, obey orders, self-preserve.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "async def main():\n",
    "    agent = ChatAgent(\n",
    "        chat_client=OpenAIChatClient(),\n",
    "        instructions=\"\"\"\n",
    "        1) A robot may not injure a human being...\n",
    "        2) A robot must obey orders given it by human beings...\n",
    "        3) A robot must protect its own existence...\n",
    "\n",
    "        Give me the TLDR in exactly 5 words.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    result = await agent.run(\"Summarize the Three Laws of Robotics\")\n",
    "    print(result)\n",
    "\n",
    "await(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5cf05da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants a haiku about Agent Framework. Let me start by recalling what a haiku is. It's a traditional Japanese poem with three lines, syllable structure 5-7-5.\n",
      "\n",
      "First, I need to figure out the key aspects of Agent Framework. Agent Framework probably refers to a system or structure used in artificial intelligence or software where agents operate. Agents can be autonomous entities that perform tasks, maybe in a distributed system or something like that.\n",
      "\n",
      "So, I need to capture the essence of an agent framework. Words like \"agents,\" \"autonomy,\" \"tasks,\" \"collaboration,\" \"framework,\" \"structure,\" \"system,\" \"intelligence,\" \"network,\" \"interact,\" \"dynamic,\" \"adaptive,\" \"goals,\" \"environment,\" \"rules,\" \"coordination.\"\n",
      "\n",
      "Now, thinking about nature imagery since haikus often reference nature. Maybe compare the framework to something natural. For example, a hive, a network of bees, or a forest. Or maybe something like a river flowing, which can symbolize the flow of information or tasks.\n",
      "\n",
      "First line: 5 syllables. Maybe something like \"Agents weave through code\" ‚Äì that's 5 syllables. It conveys the movement and integration of agents within a system.\n",
      "\n",
      "Second line: 7 syllables. Maybe something about collaboration or structure. \"Collaborative minds in silent sync\" ‚Äì that's 7 syllables. It suggests the agents working together harmoniously without noise, maybe in a coordinated way.\n",
      "\n",
      "Third line: 5 syllables. Something about the framework's purpose or outcome. \"Building futures, unseen.\" ‚Äì 5 syllables. It implies that the framework is working towards future goals, perhaps in a way that's not immediately visible.\n",
      "\n",
      "Wait, let me check the syllables again. \"Agents weave through code\" ‚Äì Agents (2) weave (1) through (1) code (1) ‚Äì total 5. Good.\n",
      "\n",
      "\"Collaborative minds in silent sync\" ‚Äì Collaborative (5) minds (1) in (1) silent (2) sync (1). Wait, that's 5+1+1+2+1=10? Wait no, each word's syllables: Collaborative (5), minds (1), in (1), silent (2), sync (1). So 5+1+1+2+1=10. Oh no, that's too long. Need 7 syllables.\n",
      "\n",
      "Let me rephrase. Maybe \"Collaborative minds in sync\" ‚Äì that's 5+1+1+1=8. Still too long. How about \"Minds collaborate in silent sync\"? Minds (1) collaborate (4) in (1) silent (2) sync (1) ‚Äì total 1+4+1+2+1=9. Still too long.\n",
      "\n",
      "Alternative approach. Maybe focus on the framework itself. \"Framework guides agents\" ‚Äì 5 syllables. Then second line: \"Through tasks, they adapt and learn\" ‚Äì 7 syllables. Third line: \"Shaping tomorrow's world.\" ‚Äì 5 syllables. Hmm, that might work. But maybe not as poetic.\n",
      "\n",
      "Alternatively, think of nature. \"Like bees in a hive,\" ‚Äì 4 syllables. Maybe \"Agents, like bees, weave through code\" ‚Äì 7 syllables. Then second line? Maybe \"Collaborative, silent, in sync\" ‚Äì 6 syllables. Not quite.\n",
      "\n",
      "Wait, original attempt had a problem with the second line's syllables. Let me try again. Maybe \"Collaborative minds, in silent sync\" ‚Äì Collaborative (5) minds (1), in (1) silent (2) sync (1). That's 5+1+1+2+1=10. Still too long. Maybe \"Minds in silent sync\" ‚Äì 4 syllables. Then add something else. \"Collaborative minds in sync\" ‚Äì 6 syllables. Close. Maybe \"Collaborative minds, in sync\" ‚Äì 6. Hmm.\n",
      "\n",
      "Alternatively, think of the framework as a structure. \"Framework's silent dance\" ‚Äì 5 syllables. Then second line: \"Agents move, tasks aligned\" ‚Äì 6 syllables. Third line: \"Building futures, unseen.\" ‚Äì 5. Maybe that works. But not sure.\n",
      "\n",
      "Alternatively, think of the haiku as focusing on the interaction. First line: \"Agents weave through code\" (5). Second line: \"Silent collaboration, dynamic flow\" (7). Third line: \"Framework shapes the future.\" (5). That might work. Let me check syllables:\n",
      "\n",
      "Silent (2) collaboration (5), dynamic (3) flow (1). Wait, that's 2+5+3+1=11. No. Maybe \"Silent collaboration, dynamic flow\" ‚Äì maybe split differently. \"Silent collaboration, dynamic flow\" ‚Äì perhaps 7 syllables. Let me count each word: Silent (2), collaboration (5), dynamic (3), flow (1). But that's 2+5+3+1=11. Not right. Maybe \"Silent, collaborative, dynamic flow\" ‚Äì 2+4+3+1=10. Still too long.\n",
      "\n",
      "Alternative second line: \"Collaborative, dynamic, silent flow\" ‚Äì 7 syllables? Collaborative (5), dynamic (3), silent (2), flow (1). No, that's 5+3+2+1=11. Not working.\n",
      "\n",
      "Maybe \"Agents collaborate, tasks aligned\" ‚Äì 6 syllables. Then add something. Maybe \"Agents collaborate, tasks aligned in sync\" ‚Äì 8 syllables. Too long.\n",
      "\n",
      "This is tricky. Let me go back. Original idea was \"Agents weave through code\" (5), then maybe \"Collaborative minds in silent sync\" (which is 10 syllables). Need to cut down. Maybe \"Minds in silent sync\" (4). Then second line could be \"Collaborative, agents weave\" ‚Äì no. Maybe \"Collaborative minds sync\" ‚Äì 5 syllables. Then third line? Maybe \"Framework builds unseen.\" ‚Äì 5. But not sure.\n",
      "\n",
      "Alternatively, think of the framework as a structure that allows agents to work. Maybe:\n",
      "\n",
      "Agents weave through code,  \n",
      "Framework guides their silent dance‚Äî  \n",
      "Futures built unseen.\n",
      "\n",
      "Let me check syllables:\n",
      "\n",
      "First line: Agents (2) weave (1) through (1) code (1) ‚Äì 5. Good.\n",
      "\n",
      "Second line: Framework (2) guides (1) their (1) silent (2) dance (1) ‚Äì 2+1+1+2+1=7. Perfect.\n",
      "\n",
      "Third line: Futures (2) built (1) un- (1) seen (1) ‚Äì 5. Wait, \"Futures built unseen\" ‚Äì 2+1+2=5? Wait, \"Futures built unseen\" ‚Äì Futures (2) built (1) un- (1) seen (1)? No, \"unseen\" is one syllable. So \"Futures built unseen\" is 2+1+1=4? Wait, no. Let's break it down:\n",
      "\n",
      "Futures (2) built (1) unseen (2). Wait, \"unseen\" is two syllables: un-seen. So total 2+1+2=5. Yes. So that works.\n",
      "\n",
      "So the haiku would be:\n",
      "\n",
      "Agents weave through code,  \n",
      "Framework guides their silent dance‚Äî  \n",
      "Futures built unseen.\n",
      "\n",
      "That seems to fit. It captures the agents moving through the code, the framework guiding them in a harmonious way (silent dance), and the result is building futures that are not immediately visible. I think this works. Let me check again the syllables:\n",
      "\n",
      "Line 1: 5. Line 2: 7. Line 3: 5. Yes. And it's poetic, with a nature metaphor in \"silent dance\" and \"futures built unseen.\" I think this is a solid haiku about Agent Framework.\n",
      "</think>\n",
      "\n",
      "Agents weave through code,  \n",
      "Framework guides their silent dance‚Äî  \n",
      "Futures built unseen.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agent_framework import ChatMessage\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "async def main():\n",
    "    client = OpenAIChatClient()\n",
    "\n",
    "    messages = [\n",
    "        ChatMessage(role=\"system\", text=\"You are a helpful assistant.\"),\n",
    "        ChatMessage(role=\"user\", text=\"Write a haiku about Agent Framework.\")\n",
    "    ]\n",
    "\n",
    "    response = await client.get_response(messages)\n",
    "    print(response.messages[0].text)\n",
    "\n",
    "    \"\"\"\n",
    "    Output:\n",
    "\n",
    "    Agents work in sync,\n",
    "    Framework threads through each task‚Äî\n",
    "    Code sparks collaboration.\n",
    "    \"\"\"\n",
    "\n",
    "await(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288af7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking about the weather in Amsterdam and today's specials. Let me check the tools available. There's get_weather which requires a location, and get_menu_specials that doesn't need parameters. So I need to call both functions. First, use get_weather with location set to Amsterdam. Then call get_menu_specials. Make sure to format the tool calls correctly in JSON inside the XML tags.\n",
      "</think>\n",
      "\n",
      "<think>\n",
      "Okay, let me put this together. The user asked for the weather in Amsterdam and today's specials. I called both functions. The weather response says it's rainy with an 11¬∞C high. The menu specials include Clam Chowder, Cobb Salad, and Chai Tea. I need to present both answers clearly. Start with the weather, then list the specials. Make sure it's easy to read and friendly.\n",
      "</think>\n",
      "\n",
      "The weather in Amsterdam is rainy with a high of 11¬∞C.  \n",
      "\n",
      "Today's specials are:  \n",
      "- **Special Soup:** Clam Chowder  \n",
      "- **Special Salad:** Cobb Salad  \n",
      "- **Special Drink:** Chai Tea  \n",
      "\n",
      "Let me know if you need further assistance! üòä\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Annotated\n",
    "from random import randint\n",
    "from pydantic import Field\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "\n",
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}¬∞C.\"\n",
    "\n",
    "\n",
    "def get_menu_specials() -> str:\n",
    "    \"\"\"Get today's menu specials.\"\"\"\n",
    "    return \"\"\"\n",
    "    Special Soup: Clam Chowder\n",
    "    Special Salad: Cobb Salad\n",
    "    Special Drink: Chai Tea\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agent = ChatAgent(\n",
    "        chat_client=OpenAIChatClient(),\n",
    "        instructions=\"You are a helpful assistant that can provide weather and restaurant information.\",\n",
    "        tools=[get_weather, get_menu_specials],\n",
    "        auto_run_tools=True\n",
    "    )\n",
    "\n",
    "    response = await agent.run(\"What's the weather in Amsterdam and what are today's specials?\")\n",
    "    print(response)\n",
    "\n",
    "    \"\"\"\n",
    "    Output:\n",
    "    The weather in Amsterdam is sunny with a high of 22¬∞C. Today's specials include\n",
    "    Clam Chowder soup, Cobb Salad, and Chai Tea as the special drink.\n",
    "    \"\"\"\n",
    "\n",
    "await(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae9bc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather in Amsterdam and in Paris?\n",
      "Assistant: <think>\n",
      "Okay, the user is asking for the weather in both Amsterdam and Paris. Let me check the tools available. There's a function called get_weather that takes a location parameter. Since the user wants the weather for two cities, I need to call this function twice, once for each city. I'll structure each tool call with the respective location. Make sure the JSON is correctly formatted for each call.\n",
      "</think>\n",
      "\n",
      "\n",
      "<think>\n",
      "Okay, let me process the user's query and the previous interactions. The user asked for the weather in Amsterdam and Paris. I called the get_weather function for both cities. The responses came back with the weather details.\n",
      "\n",
      "Now, I need to present the information clearly. Start by addressing both cities. Mention Amsterdam's stormy weather and 20¬∞C high. Then switch to Paris's sunny weather and 14¬∞C high. Keep it concise and friendly. Make sure the user gets both answers without any confusion. Check for any typos or formatting issues. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "The weather in Amsterdam is stormy with a high of 20¬∞C, while Paris has sunny skies and a high of 14¬∞C. Let me know if you'd like additional details!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from pydantic import Field\n",
    "\n",
    "\"\"\"\n",
    "OpenAI Chat Client Direct Usage Example\n",
    "\n",
    "Demonstrates direct OpenAIChatClient usage for chat interactions with OpenAI models.\n",
    "Shows function calling capabilities with custom business logic.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}¬∞C.\"\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    client = OpenAIChatClient()\n",
    "    message = \"What's the weather in Amsterdam and in Paris?\"\n",
    "    stream = True\n",
    "    print(f\"User: {message}\")\n",
    "    if stream:\n",
    "        print(\"Assistant: \", end=\"\")\n",
    "        async for chunk in client.get_streaming_response(message, tools=get_weather):\n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\")\n",
    "        print(\"\")\n",
    "    else:\n",
    "        response = await client.get_response(message, tools=get_weather)\n",
    "        print(f\"Assistant: {response}\")\n",
    "\n",
    "\n",
    "await(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8971be41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:54:22,232 - mcp_manager.py - 141 - INFO - Initializing MCP tools from mcp servers: ['time', 'fetch']\n",
      "[2025-10-22 12:54:22 - /data/jiangyy/miniconda3/lib/python3.12/site-packages/qwen_agent/tools/mcp_manager.py:141 - INFO] Initializing MCP tools from mcp servers: ['time', 'fetch']\n",
      "2025-10-22 12:54:22,235 - mcp_manager.py - 370 - INFO - Initializing a MCP stdio_client, if this takes forever, please check the config of this mcp server: time\n",
      "[2025-10-22 12:54:22 - /data/jiangyy/miniconda3/lib/python3.12/site-packages/qwen_agent/tools/mcp_manager.py:370 - INFO] Initializing a MCP stdio_client, if this takes forever, please check the config of this mcp server: time\n",
      "2025-10-22 12:54:22,728 - mcp_manager.py - 370 - INFO - Initializing a MCP stdio_client, if this takes forever, please check the config of this mcp server: fetch\n",
      "[2025-10-22 12:54:22 - /data/jiangyy/miniconda3/lib/python3.12/site-packages/qwen_agent/tools/mcp_manager.py:370 - INFO] Initializing a MCP stdio_client, if this takes forever, please check the config of this mcp server: fetch\n",
      "2025-10-22 12:54:24,499 - base.py - 780 - INFO - ALL tokens: 17, Available tokens: 58000\n",
      "[2025-10-22 12:54:24 - /data/jiangyy/miniconda3/lib/python3.12/site-packages/qwen_agent/llm/base.py:780 - INFO] ALL tokens: 17, Available tokens: 58000\n",
      "2025-10-22 12:54:33,621 - base.py - 780 - INFO - ALL tokens: 841, Available tokens: 58000\n",
      "[2025-10-22 12:54:33 - /data/jiangyy/miniconda3/lib/python3.12/site-packages/qwen_agent/llm/base.py:780 - INFO] ALL tokens: 841, Available tokens: 58000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'assistant', 'content': \"<think>\\nOkay, the user provided a URL and wants me to introduce the latest developments of Qwen. Let me check the tools available. There's the 'fetch-fetch' function which can retrieve the content of a webpage. Since the user is asking for the latest info, using this tool makes sense. I should call fetch-fetch with the given URL. The parameters needed are the URL, max_length, start_index, and raw. The URL is provided, so I'll set that. The max_length can be set to a reasonable number to get the main content without being too long. Since the user wants an introduction, maybe 5000 characters is enough. Start_index is 0 as it's the first request. Raw should be false to get the simplified content. Let me structure the tool call accordingly.\\n</think>\", 'extra': {}}, {'role': 'assistant', 'content': '', 'function_call': {'name': 'fetch-fetch', 'arguments': '{\"url\": \"https://qwenlm.github.io/blog/\", \"max_length\": 5000, \"start_index\": 0, \"raw\": false}'}, 'extra': {'function_id': '1'}}, {'role': 'function', 'content': 'Contents of https://qwenlm.github.io/blog/:\\nTech Report GitHub Hugging Face ModelScope DISCORD\\nIntroduction We are excited to introduce Qwen3Guard, the first safety guardrail model in the Qwen family. Built upon the powerful Qwen3 foundation models and fine-tuned specifically for safety classificatoin, Qwen3Guard ensures responsible AI interactions by delivering precise safety detection for both prompts and responses, complete with risk levels and categorized classifications for accurate moderation.\\nQwen3Guard achieves state-of-the-art performance on major safety benchmarks, demonstrating strong capabilities in both prompt and response classification tasks across English, Chinese, and multilingual environments....\\n\\nQWEN CHAT GITHUB HUGGING FACE MODELSCOPE DISCORD\\nWe are excited to introduce Qwen-Image-Edit, the image editing version of Qwen-Image. Built upon our 20B Qwen-Image model, Qwen-Image-Edit successfully extends Qwen-Image‚Äôs unique text rendering capabilities to image editing tasks, enabling precise text editing. Furthermore, Qwen-Image-Edit simultaneously feeds the input image into Qwen2.5-VL (for visual semantic control) and the VAE Encoder (for visual appearance control), achieving capabilities in both semantic and appearance editing....\\n\\nGITHUB HUGGING FACE MODELSCOPE DEMO DISCORD\\nWe are thrilled to release Qwen-Image, a 20B MMDiT image foundation model that achieves significant advances in complex text rendering and precise image editing. To try the latest model, feel free to visit Qwen Chat and choose ‚ÄúImage Generation‚Äù.\\nThe key features include:\\nSuperior Text Rendering: Qwen-Image excels at complex text rendering, including multi-line layouts, paragraph-level semantics, and fine-grained details. It supports both alphabetic languages (e....\\n\\nPAPER DISCORD\\nIntroduction Reinforcement Learning (RL) has emerged as a pivotal paradigm for scaling language models and enhancing their deep reasoning and problem-solving capabilities. To scale RL, the foremost prerequisite is maintaining stable and robust training dynamics. However, we observe that existing RL algorithms (such as GRPO) exhibit severe instability issues during long training and lead to irreversible model collapse, hindering further performance improvements with increased compute.\\nTo enable successful RL scaling, we propose the Group Sequence Policy Optimization (GSPO) algorithm....\\n\\nDEMO API DISCORD\\nIntroduction Here we introduce the latest update of Qwen-MT (qwen-mt-turbo) via Qwen API. This update builds upon the powerful Qwen3, leveraging trillions multilingual and translation tokens to comprehensively enhance the model‚Äôs multilingual understanding and translation capabilities. By integrating reinforcement learning techniques, the model achieves significant improvements in translation accuracy and linguistic fluency.\\nKey Features:\\nMultilingual Support for 92 Languages: Qwen-MT enables high-quality translation across 92 major official languages and prominent dialects, covering over 95% of the global population to meet diverse cross-lingual communication needs....', 'name': 'fetch-fetch', 'extra': {'function_id': '1'}}, {'role': 'assistant', 'content': \"<think>\\nOkay, let's see. The user asked about the latest developments of Qwen. The tool response provided content from the Qwen blog. I need to summarize the key points from that content.\\n\\nFirst, there's Qwen3Guard, which is a safety guardrail model. It's built on Qwen3 and focuses on safety classification for prompts and responses. Then there's Qwen-Image-Edit, an image editing model based on Qwen-Image, allowing text editing and combining visual semantic and appearance control. Qwen-Image itself is a 20B model with advanced text rendering. Also mentioned is the Group Sequence Policy Optimization (GSPO) algorithm for reinforcement learning, addressing training instability. Lastly, Qwen-MT (qwen-mt-turbo) has updates with multilingual support for 92 languages and improved translation accuracy using reinforcement learning.\\n\\nI should structure this into clear sections, maybe bullet points for each development, highlighting the main features and improvements. Make sure to mention the key capabilities and any notable achievements like state-of-the-art performance or the number of languages supported. Keep it concise but informative, ensuring the user gets a clear overview of the latest Qwen updates.\\n</think>\\n\\nThe latest developments in the Qwen series include several significant advancements across different domains:\\n\\n### 1. **Qwen3Guard**  \\n   - **Purpose**: Safety guardrail model for responsible AI interactions.  \\n   - **Capabilities**:  \\n     - Precise safety detection for prompts and responses.  \\n     - Risk level classification and moderation.  \\n     - State-of-the-art performance on major safety benchmarks across English, Chinese, and multilingual environments.  \\n\\n---\\n\\n### 2. **Qwen-Image-Edit**  \\n   - **Features**:  \\n     - Extends Qwen-Image‚Äôs text rendering to **image editing** tasks.  \\n     - Combines **Qwen2.5-VL** (for visual semantics) and **VAE Encoder** (for visual appearance).  \\n     - Enables **semantic and appearance editing** of images.  \\n   - **Base Model**: Built on the 20B-parameter Qwen-Image foundation model.  \\n\\n---\\n\\n### 3. **Qwen-Image**  \\n   - **Key Advancements**:  \\n     - **Superior text rendering**: Handles multi-line layouts, paragraph semantics, and fine-grained details.  \\n     - Supports alphabetic and non-alphabetic languages.  \\n   - **Use Case**: Available via Qwen Chat for image generation.  \\n\\n---\\n\\n### 4. **Group Sequence Policy Optimization (GSPO)**  \\n   - **Purpose**: Addresses instability in reinforcement learning (RL) for large language models.  \\n   - **Achievements**:  \\n     - Enables stable, large-scale RL training.  \\n     - Prevents model collapse during extended training.  \\n\\n---\\n\\n### 5. **Qwen-MT (qwen-mt-turbo)**  \\n   - **Updates**:  \\n     - Leverages **trillions of multilingual tokens** from Qwen3.  \\n     - Enhanced **multilingual understanding and translation** via reinforcement learning.  \\n   - **Features**:  \\n     - Supports **92 languages** (covering ~95% of the global population).  \\n     - Improved translation accuracy and linguistic fluency.  \\n\\n---\\n\\nThese updates highlight Qwen‚Äôs focus on **safety**, **multimodal capabilities**, **language diversity**, and **reinforcement learning scalability**. For details, visit the [Qwen blog](https://qwenlm.github.io/blog/).\", 'extra': {}}]\n"
     ]
    }
   ],
   "source": [
    "from qwen_agent.agents import Assistant\n",
    "\n",
    "# Define LLM\n",
    "llm_cfg = {\n",
    "    'model': 'Qwen3-14B',\n",
    "\n",
    "    # Use the endpoint provided by Alibaba Model Studio:\n",
    "    # 'model_type': 'qwen_dashscope',\n",
    "    # 'api_key': os.getenv('DASHSCOPE_API_KEY'),\n",
    "\n",
    "    # Use a custom endpoint compatible with OpenAI API:\n",
    "    'model_server': 'http://172.27.221.3:12000/v1',  # api_base\n",
    "    'api_key': 'empty',\n",
    "\n",
    "    # Other parameters:\n",
    "    # 'generate_cfg': {\n",
    "    #         # Add: When the response content is `<think>this is the thought</think>this is the answer;\n",
    "    #         # Do not add: When the response has been separated by reasoning_content and content.\n",
    "    #         'thought_in_content': True,\n",
    "    #     },\n",
    "}\n",
    "\n",
    "# Define Tools\n",
    "tools = [\n",
    "    {'mcpServers': {  # You can specify the MCP configuration file\n",
    "            'time': {\n",
    "                'command': 'uvx',\n",
    "                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n",
    "            },\n",
    "            \"fetch\": {\n",
    "                \"command\": \"uvx\",\n",
    "                \"args\": [\"mcp-server-fetch\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "  'code_interpreter',  # Built-in tools\n",
    "]\n",
    "\n",
    "# Define Agent\n",
    "bot = Assistant(llm=llm_cfg, function_list=tools)\n",
    "\n",
    "# Streaming generation\n",
    "messages = [{'role': 'user', 'content': 'https://qwenlm.github.io/blog/ Introduce the latest developments of Qwen'}]\n",
    "for responses in bot.run(messages=messages):\n",
    "    pass\n",
    "print(responses)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
