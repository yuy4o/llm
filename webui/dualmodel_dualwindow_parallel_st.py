import streamlit as st
from openai import OpenAI
import time

# é…ç½®é¡µé¢
st.set_page_config(page_title="LLM Chat", layout="wide")

# å®šä¹‰å¯ç”¨çš„æ¨¡å‹
MODELS = {
    "Qwen3-14B": "http://localhost:12000/v1",
    "Qwen3-4B": "http://localhost:12002/v1"
}

# åˆå§‹åŒ–ä¸¤ä¸ªæ¨¡å‹çš„çŠ¶æ€
if 'current_model_left' not in st.session_state:
    st.session_state.current_model_left = list(MODELS.keys())[0]
if 'current_model_right' not in st.session_state:
    st.session_state.current_model_right = list(MODELS.keys())[1]

# åˆå§‹åŒ–ä¸¤ä¸ª OpenAI å®¢æˆ·ç«¯
if 'client_left' not in st.session_state:
    st.session_state.client_left = OpenAI(
        api_key="empty",
        base_url=MODELS[st.session_state.current_model_left]
    )
if 'client_right' not in st.session_state:
    st.session_state.client_right = OpenAI(
        api_key="empty",
        base_url=MODELS[st.session_state.current_model_right]
    )

# åˆå§‹åŒ–ä¸¤ä¸ªå¯¹è¯å†å²
if "messages_left" not in st.session_state:
    st.session_state.messages_left = []
if "messages_right" not in st.session_state:
    st.session_state.messages_right = []

# æ˜¾ç¤ºæ ‡é¢˜
st.title("ğŸ’¬ LLM Chat Comparison")

# åˆ›å»ºå·¦å³ä¸¤åˆ—
left_col, right_col = st.columns(2)

# å·¦ä¾§åˆ—
with left_col:
    selected_model_left = st.selectbox(
        "é€‰æ‹©å·¦ä¾§æ¨¡å‹",
        options=list(MODELS.keys()),
        index=list(MODELS.keys()).index(st.session_state.current_model_left),
        key="left_model"
    )
    
    if selected_model_left != st.session_state.current_model_left:
        st.session_state.current_model_left = selected_model_left
        st.session_state.client_left = OpenAI(
            api_key="empty",
            base_url=MODELS[selected_model_left]
        )
        st.session_state.messages_left = []
        st.rerun()

    # æ˜¾ç¤ºå·¦ä¾§èŠå¤©å†å²
    for message in st.session_state.messages_left:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# å³ä¾§åˆ—
with right_col:
    selected_model_right = st.selectbox(
        "é€‰æ‹©å³ä¾§æ¨¡å‹",
        options=list(MODELS.keys()),
        index=list(MODELS.keys()).index(st.session_state.current_model_right),
        key="right_model"
    )
    
    if selected_model_right != st.session_state.current_model_right:
        st.session_state.current_model_right = selected_model_right
        st.session_state.client_right = OpenAI(
            api_key="empty",
            base_url=MODELS[selected_model_right]
        )
        st.session_state.messages_right = []
        st.rerun()

    # æ˜¾ç¤ºå³ä¾§èŠå¤©å†å²
    for message in st.session_state.messages_right:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("What's up?"):
    # åˆ›å»ºçº¿ç¨‹å®‰å…¨çš„å˜é‡æ¥å­˜å‚¨å“åº”
    responses = {'left': '', 'right': ''}
    message_placeholders = {}
    
    # åœ¨ä¸»çº¿ç¨‹ä¸­åˆ›å»ºUIå…ƒç´ 
    for side in ['left', 'right']:
        col = left_col if side == "left" else right_col
        with col:
            with st.chat_message("user"):
                st.markdown(prompt)
            with st.chat_message("assistant"):
                message_placeholders[side] = st.empty()
    
    # åœ¨åˆ›å»ºçº¿ç¨‹å‰è·å–æ¨¡å‹ä¿¡æ¯
    model_info = {
        'left': st.session_state.current_model_left,
        'right': st.session_state.current_model_right
    }
    
    def generate_response(side, client, messages, model_name):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        messages.append({"role": "user", "content": prompt})
        
        # åˆ›å»ºæµå¼å“åº”
        stream = client.chat.completions.create(
            model=model_name,  # ä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹åç§°
            messages=[{"role": m["role"], "content": m["content"]} for m in messages],
            stream=True,
            temperature=0.7,
        )
        
        # é€å­—æ˜¾ç¤ºå›å¤
        response = ''
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                response += chunk.choices[0].delta.content
                responses[side] = response
                time.sleep(0.01)
        
        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
        messages.append({"role": "assistant", "content": response})
    
    import threading
    
    # åˆ›å»ºä¸¤ä¸ªçº¿ç¨‹
    threads = []
    for side, client, messages in [
        ("left", st.session_state.client_left, st.session_state.messages_left),
        ("right", st.session_state.client_right, st.session_state.messages_right)
    ]:
        thread = threading.Thread(
            target=generate_response,
            args=(side, client, messages, model_info[side])  # ä¼ å…¥æ¨¡å‹åç§°
        )
        threads.append(thread)
        thread.start()
    
    # åœ¨å“åº”ç”Ÿæˆè¿‡ç¨‹ä¸­æ›´æ–°UI
    while any(thread.is_alive() for thread in threads):
        for side in ['left', 'right']:
            message_placeholders[side].markdown(responses[side] + "â–Œ")
        time.sleep(0.1)
    
    # æ˜¾ç¤ºæœ€ç»ˆå“åº”
    for side in ['left', 'right']:
        message_placeholders[side].markdown(responses[side])
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join()