import streamlit as st
from openai import OpenAI
import time

# é…ç½®é¡µé¢
st.set_page_config(page_title="LLM Chat", layout="wide")

# å®šä¹‰å¯ç”¨çš„æ¨¡å‹
MODELS = {
    "/data/wenhr/modelhub/Qwen2.5-Coder-32B-Instruct": "http://localhost:8777/v1",
    "/data/wenhr/modelhub/QwQ-32B-Preview": "http://localhost:8778/v1"
}

# åˆå§‹åŒ–ä¸¤ä¸ªæ¨¡å‹çš„çŠ¶æ€
if 'current_model_left' not in st.session_state:
    st.session_state.current_model_left = list(MODELS.keys())[0]
if 'current_model_right' not in st.session_state:
    st.session_state.current_model_right = list(MODELS.keys())[1]

# åˆå§‹åŒ–ä¸¤ä¸ª OpenAI å®¢æˆ·ç«¯
if 'client_left' not in st.session_state:
    st.session_state.client_left = OpenAI(
        api_key="empty",
        base_url=MODELS[st.session_state.current_model_left]
    )
if 'client_right' not in st.session_state:
    st.session_state.client_right = OpenAI(
        api_key="empty",
        base_url=MODELS[st.session_state.current_model_right]
    )

# åˆå§‹åŒ–ä¸¤ä¸ªå¯¹è¯å†å²
if "messages_left" not in st.session_state:
    st.session_state.messages_left = []
if "messages_right" not in st.session_state:
    st.session_state.messages_right = []

# æ˜¾ç¤ºæ ‡é¢˜
st.title("ğŸ’¬ LLM Chat Comparison")

# åˆ›å»ºå·¦å³ä¸¤åˆ—
left_col, right_col = st.columns(2)

# å·¦ä¾§åˆ—
with left_col:
    selected_model_left = st.selectbox(
        "é€‰æ‹©å·¦ä¾§æ¨¡å‹",
        options=list(MODELS.keys()),
        index=list(MODELS.keys()).index(st.session_state.current_model_left),
        key="left_model"
    )
    
    if selected_model_left != st.session_state.current_model_left:
        st.session_state.current_model_left = selected_model_left
        st.session_state.client_left = OpenAI(
            api_key="empty",
            base_url=MODELS[selected_model_left]
        )
        st.session_state.messages_left = []
        st.rerun()

    # æ˜¾ç¤ºå·¦ä¾§èŠå¤©å†å²
    for message in st.session_state.messages_left:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# å³ä¾§åˆ—
with right_col:
    selected_model_right = st.selectbox(
        "é€‰æ‹©å³ä¾§æ¨¡å‹",
        options=list(MODELS.keys()),
        index=list(MODELS.keys()).index(st.session_state.current_model_right),
        key="right_model"
    )
    
    if selected_model_right != st.session_state.current_model_right:
        st.session_state.current_model_right = selected_model_right
        st.session_state.client_right = OpenAI(
            api_key="empty",
            base_url=MODELS[selected_model_right]
        )
        st.session_state.messages_right = []
        st.rerun()

    # æ˜¾ç¤ºå³ä¾§èŠå¤©å†å²
    for message in st.session_state.messages_right:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("What's up?"):
    # åŒæ—¶å¤„ç†å·¦å³ä¸¤ä¾§çš„å¯¹è¯
    for side, client, messages in [
        ("left", st.session_state.client_left, st.session_state.messages_left),
        ("right", st.session_state.client_right, st.session_state.messages_right)
    ]:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        messages.append({"role": "user", "content": prompt})
        
        # è·å–å¯¹åº”çš„åˆ—
        col = left_col if side == "left" else right_col
        
        with col:
            with st.chat_message("user"):
                st.markdown(prompt)

            # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å ä½
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                
                # åˆ›å»ºæµå¼å“åº”
                stream = client.chat.completions.create(
                    model=st.session_state.current_model_left if side == "left" else st.session_state.current_model_right,
                    messages=[{"role": m["role"], "content": m["content"]} for m in messages],
                    stream=True,
                    temperature=0.7,
                )
                
                # é€å­—æ˜¾ç¤ºå›å¤
                for chunk in stream:
                    if chunk.choices[0].delta.content is not None:
                        full_response += chunk.choices[0].delta.content
                        message_placeholder.markdown(full_response + "â–Œ")
                        time.sleep(0.01)
                
                # æ˜¾ç¤ºå®Œæ•´å›å¤
                message_placeholder.markdown(full_response)
            
            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
            messages.append({"role": "assistant", "content": full_response})